{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491efac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T02:15:51.452891Z",
     "iopub.status.busy": "2025-11-18T02:15:51.452612Z",
     "iopub.status.idle": "2025-11-18T02:17:42.068027Z",
     "shell.execute_reply": "2025-11-18T02:17:42.066923Z"
    },
    "papermill": {
     "duration": 110.619982,
     "end_time": "2025-11-18T02:17:42.069741",
     "exception": false,
     "start_time": "2025-11-18T02:15:51.449759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\r\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\r\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (19.0.1)\r\n",
      "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (3.0.1)\r\n",
      "Collecting pylatexenc\r\n",
      "  Downloading pylatexenc-2.10.tar.gz (162 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\r\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\r\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\r\n",
      "Collecting math-verify[antlr4_9_3]\r\n",
      "  Downloading math_verify-0.8.0-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.1.3)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\r\n",
      "Collecting pyarrow\r\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\r\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.3.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.5.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (6.33.0)\r\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.12.4)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\r\n",
      "Collecting latex2sympy2_extended==1.10.2 (from math-verify[antlr4_9_3])\r\n",
      "  Downloading latex2sympy2_extended-1.10.2-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime<=4.13.2,>=4.9.3 in /usr/local/lib/python3.11/dist-packages (from latex2sympy2_extended==1.10.2->math-verify[antlr4_9_3]) (4.9.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading latex2sympy2_extended-1.10.2-py3-none-any.whl (207 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.9/207.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading math_verify-0.8.0-py3-none-any.whl (29 kB)\r\n",
      "Building wheels for collected packages: pylatexenc\r\n",
      "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=45f4c22e6b06acba5e22f5d90ba226fefb4148ad260a2379d1a6eaf3590e9150\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/7a/33/9fdd892f784ed4afda62b685ae3703adf4c91aa0f524c28f03\r\n",
      "Successfully built pylatexenc\r\n",
      "Installing collected packages: pylatexenc, pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, latex2sympy2_extended, nvidia-cusolver-cu12, math-verify\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed latex2sympy2_extended-1.10.2 math-verify-0.8.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0 pylatexenc-2.10\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting numpy>=1.22.0 (from scikit-learn)\r\n",
      "  Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scipy>=1.8.0 (from scikit-learn)\r\n",
      "  Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\r\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\r\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\r\n",
      "  Attempting uninstall: threadpoolctl\r\n",
      "    Found existing installation: threadpoolctl 3.6.0\r\n",
      "    Uninstalling threadpoolctl-3.6.0:\r\n",
      "      Successfully uninstalled threadpoolctl-3.6.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.5.2\r\n",
      "    Uninstalling joblib-1.5.2:\r\n",
      "      Successfully uninstalled joblib-1.5.2\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.15.3\r\n",
      "    Uninstalling scipy-1.15.3:\r\n",
      "      Successfully uninstalled scipy-1.15.3\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.5 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.5 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.5 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.5 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed joblib-1.5.2 numpy-2.3.5 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/kaggle/working/src\n",
      "evaluate.py  hf_rollout.py  rollout.py\tvllm_rollout.py\r\n",
      "finetune.py  prepare.py     verifier\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# NOTE: Make sure you have added the dataset into the notebook\n",
    "# Move the code to working directory\n",
    "!mkdir /kaggle/working/src\n",
    "!cp -r /kaggle/input/finetune-code/* /kaggle/working/src\n",
    "\n",
    "# install necessary packages, as Kaggle will clear installed packages when restart the kernel.\n",
    "%pip install torch numpy pandas transformers peft pyarrow pybind11 pylatexenc datasets tiktoken wandb tqdm matplotlib math-verify[antlr4_9_3]\n",
    "%pip install --upgrade --force-reinstall scikit-learn\n",
    "\n",
    "%cd /kaggle/working/src\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb5153c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T02:17:42.121746Z",
     "iopub.status.busy": "2025-11-18T02:17:42.121430Z",
     "iopub.status.idle": "2025-11-18T02:18:05.719886Z",
     "shell.execute_reply": "2025-11-18T02:18:05.718901Z"
    },
    "papermill": {
     "duration": 23.62611,
     "end_time": "2025-11-18T02:18:05.721515",
     "exception": false,
     "start_time": "2025-11-18T02:17:42.095405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: 'Qwen/Qwen3-0.6B-Base'\r\n",
      "tokenizer_config.json: 9.68kB [00:00, 33.7MB/s]\r\n",
      "vocab.json: 2.78MB [00:00, 66.9MB/s]\r\n",
      "merges.txt: 1.67MB [00:00, 133MB/s]\r\n",
      "tokenizer.json: 7.03MB [00:00, 167MB/s]\r\n",
      "Loading dataset: 'ricdomolm/MATH-500'\r\n",
      "README.md: 1.80kB [00:00, 1.42MB/s]\r\n",
      "data/train-00000-of-00001.parquet: 100%|███| 4.72M/4.72M [00:00<00:00, 6.34MB/s]\r\n",
      "data/test-00000-of-00001.parquet: 100%|███████| 199k/199k [00:00<00:00, 882kB/s]\r\n",
      "Generating train split: 100%|██| 12000/12000 [00:00<00:00, 291764.14 examples/s]\r\n",
      "Generating test split: 100%|███████| 500/500 [00:00<00:00, 125675.80 examples/s]\r\n",
      "--- DEBUG MODE: Using 600 samples (5% of original) ---\r\n",
      "Dataset split into 540 training and 60 validation examples.\r\n",
      "\r\n",
      "Tokenizing and formatting datasets...\r\n",
      "Map (num_proc=4): 100%|███████████████| 540/540 [00:01<00:00, 283.78 examples/s]\r\n",
      "Map (num_proc=4): 100%|██████████████████| 60/60 [00:01<00:00, 36.24 examples/s]\r\n",
      "Filter (num_proc=4): 100%|███████████| 540/540 [00:00<00:00, 1603.50 examples/s]\r\n",
      "Filter (num_proc=4): 100%|██████████████| 60/60 [00:00<00:00, 266.06 examples/s]\r\n",
      "Final training samples: 458\r\n",
      "Final validation samples: 55\r\n",
      "\r\n",
      "--- DATASET STATS ---\r\n",
      "Sample of first training example:\r\n",
      " <|im_start|>user\r\n",
      "The two solutions of the equation $x^2+bx+48=0$ are in the ratio of 3 to 1 for some values of $b$. What is the largest possible value of $b$?\r\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "<think>\r\n",
      "\r\n",
      "</think>\r\n",
      "\r\n",
      "For this problem, we make use of the correspondence between sums/products of roots and coefficients of a polynomial.\r\n",
      "\r\n",
      "Denote the two roots of the equation $\\alpha$ and $\\beta$. We know that $\\alpha\\beta = 48$, and $\\alpha/\\beta = 3 \\implies \\alpha = 3\\beta$.\r\n",
      "\r\n",
      "So $ b = -\\alpha - \\beta = -4\\beta$. To maximize $b$, we want to make $\\beta$ negative and as large as possible. Given the relationship that $\\alpha = 3\\beta$ and that $\\alpha*\\beta = 48$, we see that $\\beta = 4$ or $-4$. Clearly $-4$ maximizes $b$, and $b = \\boxed{16}$.<|im_end|>\r\n",
      "\r\n",
      "\r\n",
      "Max sequence length: 509\r\n",
      "Average sequence length: 240.18\r\n",
      "\r\n",
      "Saving training data to '/kaggle/working/src/data/train.pkl'...\r\n",
      "Saving validation data to '/kaggle/working/src/data/val.pkl'...\r\n",
      "--- PREPARATION COMPLETE ---\r\n"
     ]
    }
   ],
   "source": [
    "!python prepare.py --debug #prepare data firstly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bba24d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T02:18:05.774756Z",
     "iopub.status.busy": "2025-11-18T02:18:05.773954Z",
     "iopub.status.idle": "2025-11-18T02:20:42.889337Z",
     "shell.execute_reply": "2025-11-18T02:20:42.888385Z"
    },
    "papermill": {
     "duration": 157.143429,
     "end_time": "2025-11-18T02:20:42.890850",
     "exception": false,
     "start_time": "2025-11-18T02:18:05.747421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 02:18:14.323227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1763432294.503920     208 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1763432294.554736     208 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "\r\n",
      "A module that was compiled using NumPy 1.x cannot be run in\r\n",
      "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\r\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\r\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\r\n",
      "\r\n",
      "If you are a user of the module, the easiest solution will be to\r\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\r\n",
      "We expect that some modules will need time to support NumPy 2.\r\n",
      "\r\n",
      "Traceback (most recent call last):  File \"/kaggle/working/src/finetune.py\", line 16, in <module>\r\n",
      "    from peft import LoraConfig, get_peft_model\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/__init__.py\", line 17, in <module>\r\n",
      "    from .auto import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/auto.py\", line 31, in <module>\r\n",
      "    from .config import PeftConfig\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/config.py\", line 24, in <module>\r\n",
      "    from .utils import CONFIG_NAME, PeftType, TaskType\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/__init__.py\", line 17, in <module>\r\n",
      "    from .other import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/other.py\", line 35, in <module>\r\n",
      "    from transformers import PreTrainedModel\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\r\n",
      "    module = self._get_module(self._class_to_module[name])\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\r\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 73, in <module>\r\n",
      "    from .loss.loss_utils import LOSS_MAPPING\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 21, in <module>\r\n",
      "    from .loss_d_fine import DFineForObjectDetectionLoss\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_d_fine.py\", line 21, in <module>\r\n",
      "    from .loss_for_object_detection import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_for_object_detection.py\", line 32, in <module>\r\n",
      "    from transformers.image_transforms import center_to_corners_format\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\r\n",
      "    import tensorflow as tf\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\r\n",
      "    importlib.import_module(\"keras.src.optimizers\")\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\r\n",
      "    from keras.api import DTypePolicy\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 8, in <module>\r\n",
      "    from keras.api import activations\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/activations/__init__.py\", line 7, in <module>\r\n",
      "    from keras.src.activations import deserialize\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/__init__.py\", line 13, in <module>\r\n",
      "    from keras.src import visualization\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/__init__.py\", line 2, in <module>\r\n",
      "    from keras.src.visualization import plot_image_gallery\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_image_gallery.py\", line 13, in <module>\r\n",
      "    import matplotlib.pyplot as plt\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\r\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\r\n",
      "    from matplotlib.colors import Colormap, is_color_like\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\r\n",
      "    from matplotlib import _api, _cm, cbook, scale\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\r\n",
      "    from matplotlib.ticker import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\r\n",
      "    from matplotlib import transforms as mtransforms\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\r\n",
      "    from matplotlib._path import (\r\n",
      "AttributeError: _ARRAY_API not found\r\n",
      "\r\n",
      "A module that was compiled using NumPy 1.x cannot be run in\r\n",
      "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\r\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\r\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\r\n",
      "\r\n",
      "If you are a user of the module, the easiest solution will be to\r\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\r\n",
      "We expect that some modules will need time to support NumPy 2.\r\n",
      "\r\n",
      "Traceback (most recent call last):  File \"/kaggle/working/src/finetune.py\", line 16, in <module>\r\n",
      "    from peft import LoraConfig, get_peft_model\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/__init__.py\", line 17, in <module>\r\n",
      "    from .auto import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/auto.py\", line 31, in <module>\r\n",
      "    from .config import PeftConfig\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/config.py\", line 24, in <module>\r\n",
      "    from .utils import CONFIG_NAME, PeftType, TaskType\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/__init__.py\", line 17, in <module>\r\n",
      "    from .other import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/other.py\", line 35, in <module>\r\n",
      "    from transformers import PreTrainedModel\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\r\n",
      "    module = self._get_module(self._class_to_module[name])\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\r\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 73, in <module>\r\n",
      "    from .loss.loss_utils import LOSS_MAPPING\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 21, in <module>\r\n",
      "    from .loss_d_fine import DFineForObjectDetectionLoss\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_d_fine.py\", line 21, in <module>\r\n",
      "    from .loss_for_object_detection import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_for_object_detection.py\", line 32, in <module>\r\n",
      "    from transformers.image_transforms import center_to_corners_format\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\r\n",
      "    import tensorflow as tf\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\r\n",
      "    importlib.import_module(\"keras.src.optimizers\")\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\r\n",
      "    from keras.api import DTypePolicy\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 34, in <module>\r\n",
      "    from keras.api import visualization\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/visualization/__init__.py\", line 11, in <module>\r\n",
      "    from keras.src.visualization.plot_bounding_box_gallery import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_bounding_box_gallery.py\", line 12, in <module>\r\n",
      "    from matplotlib import patches  # For legend patches\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\r\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\r\n",
      "    from matplotlib.colors import Colormap, is_color_like\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\r\n",
      "    from matplotlib import _api, _cm, cbook, scale\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\r\n",
      "    from matplotlib.ticker import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\r\n",
      "    from matplotlib import transforms as mtransforms\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\r\n",
      "    from matplotlib._path import (\r\n",
      "AttributeError: _ARRAY_API not found\r\n",
      "Loading model and tokenizer from Qwen/Qwen3-0.6B-Base...\r\n",
      "config.json: 100%|█████████████████████████████| 727/727 [00:00<00:00, 4.61MB/s]\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "model.safetensors: 100%|████████████████████| 1.19G/1.19G [00:03<00:00, 310MB/s]\r\n",
      "generation_config.json: 100%|███████████████████| 138/138 [00:00<00:00, 961kB/s]\r\n",
      "Loaded 458 examples from /kaggle/working/src/data/train.pkl\r\n",
      "Loaded 55 examples from /kaggle/working/src/data/val.pkl\r\n",
      "Setting up optimizer: lora\r\n",
      "Setting up LoRA with rank=8\r\n",
      "Starting training...\r\n",
      "\r\n",
      "--- Epoch 1/1 ---\r\n",
      "Training:  17%|█████▍                          | 39/229 [00:18<01:06,  2.86it/s]Step 10: Train Loss = 0.5294\r\n",
      "Training:  34%|███████████                     | 79/229 [00:38<01:11,  2.09it/s]Step 20: Train Loss = 0.4654\r\n",
      "Training:  52%|████████████████               | 119/229 [00:57<00:49,  2.24it/s]Step 30: Train Loss = 0.7499\r\n",
      "Training:  69%|█████████████████████▌         | 159/229 [01:15<00:26,  2.61it/s]Step 40: Train Loss = 0.7719\r\n",
      "Training:  87%|██████████████████████████▉    | 199/229 [01:34<00:13,  2.21it/s]Step 50: Train Loss = 0.7834\r\n",
      "\r\n",
      "Running validation...\r\n",
      "\r\n",
      "Validating:   0%|                                        | 0/28 [00:00<?, ?it/s]\u001b[A\r\n",
      "Validating:   4%|█▏                              | 1/28 [00:00<00:05,  5.17it/s]\u001b[A\r\n",
      "Validating:   7%|██▎                             | 2/28 [00:00<00:05,  4.41it/s]\u001b[A\r\n",
      "Validating:  11%|███▍                            | 3/28 [00:00<00:05,  4.73it/s]\u001b[A\r\n",
      "Validating:  14%|████▌                           | 4/28 [00:00<00:05,  4.60it/s]\u001b[A\r\n",
      "Validating:  18%|█████▋                          | 5/28 [00:01<00:05,  4.54it/s]\u001b[A\r\n",
      "Validating:  21%|██████▊                         | 6/28 [00:01<00:05,  4.17it/s]\u001b[A\r\n",
      "Validating:  25%|████████                        | 7/28 [00:01<00:04,  4.69it/s]\u001b[A\r\n",
      "Validating:  29%|█████████▏                      | 8/28 [00:01<00:03,  5.11it/s]\u001b[A\r\n",
      "Validating:  32%|██████████▎                     | 9/28 [00:01<00:03,  5.43it/s]\u001b[A\r\n",
      "Validating:  36%|███████████                    | 10/28 [00:02<00:03,  4.82it/s]\u001b[A\r\n",
      "Validating:  39%|████████████▏                  | 11/28 [00:02<00:03,  4.69it/s]\u001b[A\r\n",
      "Validating:  43%|█████████████▎                 | 12/28 [00:02<00:03,  4.39it/s]\u001b[A\r\n",
      "Validating:  46%|██████████████▍                | 13/28 [00:02<00:03,  4.93it/s]\u001b[A\r\n",
      "Validating:  50%|███████████████▌               | 14/28 [00:02<00:02,  4.90it/s]\u001b[A\r\n",
      "Validating:  54%|████████████████▌              | 15/28 [00:03<00:02,  5.17it/s]\u001b[A\r\n",
      "Validating:  57%|█████████████████▋             | 16/28 [00:03<00:02,  4.49it/s]\u001b[A\r\n",
      "Validating:  61%|██████████████████▊            | 17/28 [00:03<00:02,  4.33it/s]\u001b[A\r\n",
      "Validating:  64%|███████████████████▉           | 18/28 [00:03<00:02,  4.69it/s]\u001b[A\r\n",
      "Validating:  68%|█████████████████████          | 19/28 [00:04<00:01,  4.72it/s]\u001b[A\r\n",
      "Validating:  71%|██████████████████████▏        | 20/28 [00:04<00:01,  4.27it/s]\u001b[A\r\n",
      "Validating:  75%|███████████████████████▎       | 21/28 [00:04<00:01,  4.32it/s]\u001b[A\r\n",
      "Validating:  79%|████████████████████████▎      | 22/28 [00:04<00:01,  4.24it/s]\u001b[A\r\n",
      "Validating:  82%|█████████████████████████▍     | 23/28 [00:04<00:01,  4.63it/s]\u001b[A\r\n",
      "Validating:  86%|██████████████████████████▌    | 24/28 [00:05<00:00,  4.97it/s]\u001b[A\r\n",
      "Validating:  89%|███████████████████████████▋   | 25/28 [00:05<00:00,  4.47it/s]\u001b[A\r\n",
      "Validating:  93%|████████████████████████████▊  | 26/28 [00:05<00:00,  4.48it/s]\u001b[A\r\n",
      "Validating:  96%|█████████████████████████████▉ | 27/28 [00:05<00:00,  4.47it/s]\u001b[A\r\n",
      "Validating: 100%|███████████████████████████████| 28/28 [00:05<00:00,  4.69it/s]\r\n",
      "Step 50: Validation Loss = 0.8538\r\n",
      "  -> New best validation loss! Saving model to /kaggle/working/src/saves/lora-tuned\r\n",
      "Training: 100%|███████████████████████████████| 229/229 [01:55<00:00,  1.98it/s]\r\n",
      "\r\n",
      "Training finished. Running one final evaluation...\r\n",
      "Final Validation: 100%|█████████████████████████| 28/28 [00:06<00:00,  4.66it/s]\r\n",
      "Final Validation Loss = 0.8465\r\n",
      "  -> Final model was the best! Saving model to /kaggle/working/src/saves/lora-tuned\r\n",
      "\r\n",
      "Process complete. Best model is saved in /kaggle/working/src/saves/lora-tuned\r\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Make sure you turn on the GPU when running the script\n",
    "!python finetune.py --optimization_method \"lora\" --output_dir \"saves/lora-tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10177460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T02:20:42.986810Z",
     "iopub.status.busy": "2025-11-18T02:20:42.986178Z",
     "iopub.status.idle": "2025-11-18T02:44:07.051627Z",
     "shell.execute_reply": "2025-11-18T02:44:07.050625Z"
    },
    "papermill": {
     "duration": 1404.123871,
     "end_time": "2025-11-18T02:44:07.053364",
     "exception": false,
     "start_time": "2025-11-18T02:20:42.929493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 02:20:49.690518: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1763432449.713949     258 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1763432449.720897     258 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "\r\n",
      "A module that was compiled using NumPy 1.x cannot be run in\r\n",
      "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\r\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\r\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\r\n",
      "\r\n",
      "If you are a user of the module, the easiest solution will be to\r\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\r\n",
      "We expect that some modules will need time to support NumPy 2.\r\n",
      "\r\n",
      "Traceback (most recent call last):  File \"/kaggle/working/src/rollout.py\", line 10, in <module>\r\n",
      "    from peft import PeftModel # Used for loading LoRA adapters\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/__init__.py\", line 17, in <module>\r\n",
      "    from .auto import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/auto.py\", line 31, in <module>\r\n",
      "    from .config import PeftConfig\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/config.py\", line 24, in <module>\r\n",
      "    from .utils import CONFIG_NAME, PeftType, TaskType\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/__init__.py\", line 17, in <module>\r\n",
      "    from .other import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/other.py\", line 35, in <module>\r\n",
      "    from transformers import PreTrainedModel\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\r\n",
      "    module = self._get_module(self._class_to_module[name])\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\r\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 73, in <module>\r\n",
      "    from .loss.loss_utils import LOSS_MAPPING\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 21, in <module>\r\n",
      "    from .loss_d_fine import DFineForObjectDetectionLoss\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_d_fine.py\", line 21, in <module>\r\n",
      "    from .loss_for_object_detection import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_for_object_detection.py\", line 32, in <module>\r\n",
      "    from transformers.image_transforms import center_to_corners_format\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\r\n",
      "    import tensorflow as tf\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\r\n",
      "    importlib.import_module(\"keras.src.optimizers\")\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\r\n",
      "    from keras.api import DTypePolicy\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 8, in <module>\r\n",
      "    from keras.api import activations\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/activations/__init__.py\", line 7, in <module>\r\n",
      "    from keras.src.activations import deserialize\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/__init__.py\", line 13, in <module>\r\n",
      "    from keras.src import visualization\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/__init__.py\", line 2, in <module>\r\n",
      "    from keras.src.visualization import plot_image_gallery\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_image_gallery.py\", line 13, in <module>\r\n",
      "    import matplotlib.pyplot as plt\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\r\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\r\n",
      "    from matplotlib.colors import Colormap, is_color_like\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\r\n",
      "    from matplotlib import _api, _cm, cbook, scale\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\r\n",
      "    from matplotlib.ticker import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\r\n",
      "    from matplotlib import transforms as mtransforms\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\r\n",
      "    from matplotlib._path import (\r\n",
      "AttributeError: _ARRAY_API not found\r\n",
      "\r\n",
      "A module that was compiled using NumPy 1.x cannot be run in\r\n",
      "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\r\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\r\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\r\n",
      "\r\n",
      "If you are a user of the module, the easiest solution will be to\r\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\r\n",
      "We expect that some modules will need time to support NumPy 2.\r\n",
      "\r\n",
      "Traceback (most recent call last):  File \"/kaggle/working/src/rollout.py\", line 10, in <module>\r\n",
      "    from peft import PeftModel # Used for loading LoRA adapters\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/__init__.py\", line 17, in <module>\r\n",
      "    from .auto import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/auto.py\", line 31, in <module>\r\n",
      "    from .config import PeftConfig\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/config.py\", line 24, in <module>\r\n",
      "    from .utils import CONFIG_NAME, PeftType, TaskType\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/__init__.py\", line 17, in <module>\r\n",
      "    from .other import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/utils/other.py\", line 35, in <module>\r\n",
      "    from transformers import PreTrainedModel\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\r\n",
      "    module = self._get_module(self._class_to_module[name])\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\r\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 73, in <module>\r\n",
      "    from .loss.loss_utils import LOSS_MAPPING\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 21, in <module>\r\n",
      "    from .loss_d_fine import DFineForObjectDetectionLoss\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_d_fine.py\", line 21, in <module>\r\n",
      "    from .loss_for_object_detection import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_for_object_detection.py\", line 32, in <module>\r\n",
      "    from transformers.image_transforms import center_to_corners_format\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\r\n",
      "    import tensorflow as tf\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\r\n",
      "    importlib.import_module(\"keras.src.optimizers\")\r\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\r\n",
      "    from keras.api import DTypePolicy\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 34, in <module>\r\n",
      "    from keras.api import visualization\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/api/visualization/__init__.py\", line 11, in <module>\r\n",
      "    from keras.src.visualization.plot_bounding_box_gallery import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_bounding_box_gallery.py\", line 12, in <module>\r\n",
      "    from matplotlib import patches  # For legend patches\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\r\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\r\n",
      "    from matplotlib.colors import Colormap, is_color_like\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\r\n",
      "    from matplotlib import _api, _cm, cbook, scale\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\r\n",
      "    from matplotlib.ticker import (\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\r\n",
      "    from matplotlib import transforms as mtransforms\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\r\n",
      "    from matplotlib._path import (\r\n",
      "AttributeError: _ARRAY_API not found\r\n",
      "Loading base model: Qwen/Qwen3-0.6B-Base\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "LoRA adapter specified. Loading from local path: saves/lora-tuned\r\n",
      "Successfully merged LoRA adapter into the base model.\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 1/8\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 2/8\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 3/8\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 4/8\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 5/8\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 6/8\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 7/8\r\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\r\n",
      "Processed batch 8/8\r\n",
      "Output will be saved to: /kaggle/working/src/output/qwen3_0.6b_base_nosys_it_lora_debug.jsonl\r\n",
      "Saved generations to /kaggle/working/src/output/qwen3_0.6b_base_nosys_it_lora_debug.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!python rollout.py --model \"Qwen/Qwen3-0.6B-Base\" --lora_path \"saves/lora-tuned\" --output_file \"output/qwen3_0.6b_base_nosys_it_lora_debug.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777b1e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T02:44:07.137936Z",
     "iopub.status.busy": "2025-11-18T02:44:07.137143Z",
     "iopub.status.idle": "2025-11-18T02:44:12.777244Z",
     "shell.execute_reply": "2025-11-18T02:44:12.776218Z"
    },
    "papermill": {
     "duration": 5.684266,
     "end_time": "2025-11-18T02:44:12.778695",
     "exception": false,
     "start_time": "2025-11-18T02:44:07.094429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluation complete.\r\n",
      "Overall Accuracy: 15.40%\r\n",
      "Scored results saved to output/qwen3_0.6b_base_nosys_it_lora_debug_evaled.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!python evaluate.py --input_file \"output/qwen3_0.6b_base_nosys_it_lora_debug.jsonl\" --output_file \"output/qwen3_0.6b_base_nosys_it_lora_debug_evaled.jsonl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1705.236734,
   "end_time": "2025-11-18T02:44:13.137765",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-18T02:15:47.901031",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
